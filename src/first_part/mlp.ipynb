{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import os\n",
    "from typing import List\n",
    "from matrices import confusion_matrix, plot_confusion_matrix\n",
    "from metrics import calculate_metrics, update_results, build_summary, plot_leaning_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(filepath: str, columns: List[str], transpose: bool, sep: str = ',') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carrega o dataset EMG e organiza as colunas.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Caminho para o arquivo.\n",
    "        columns (List[str]): Lista com os nomes das colunas.\n",
    "        transpose (bool): Transpor o DataFrame.\n",
    "        sep (str): Separador dos dados.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com dados dos sensores e classes.\n",
    "    \"\"\"\n",
    "    if transpose:\n",
    "        df: pd.DataFrame = pd.read_csv(filepath, header=None, sep=sep).T\n",
    "    else:\n",
    "        df: pd.DataFrame = pd.read_csv(filepath, sep=sep)\n",
    "    \n",
    "    df.columns = columns\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x         y  spiral\n",
      "0  15.07298  -1.56346     1.0\n",
      "1 -15.43986   0.16502    -1.0\n",
      "2  -9.26071  12.24981    -1.0\n",
      "3   7.59201   7.56913    -1.0\n",
      "4  -2.37130 -10.69521     1.0\n"
     ]
    }
   ],
   "source": [
    "columns = [\"x\", \"y\", \"spiral\"]\n",
    "\n",
    "df: pd.DataFrame = load_csv_data(filepath = \"../../resources/spiral.csv\", columns = columns, transpose = False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df: pd.DataFrame) -> None:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.scatter(df[df['spiral'] == 1.0]['x'], \n",
    "                df[df['spiral'] == 1.0]['y'], \n",
    "                color='blue', label='Classe 1.0', alpha=0.7)\n",
    "\n",
    "    plt.scatter(df[df['spiral'] == -1.0]['x'], \n",
    "                df[df['spiral'] == -1.0]['y'], \n",
    "                color='red', label='Classe -1.0', alpha=0.7)\n",
    "\n",
    "    plt.title('Gráfico de Dispersão (Espalhamento)', fontsize=16)\n",
    "    plt.xlabel('X', fontsize=14)\n",
    "    plt.ylabel('Y', fontsize=14)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_data(data_frame: pd.DataFrame) -> None:\n",
    "    \"\"\"Plota os dados de treinamento.\"\"\"\n",
    "    plt.scatter(data_frame[data_frame['spiral'] == 1.0]['x'],\n",
    "                data_frame[data_frame['spiral'] == 1.0]['y'], \n",
    "                color='blue', label='Classe 1.0', alpha=0.7)\n",
    "    plt.scatter(data_frame[data_frame['spiral'] == -1.0]['x'], \n",
    "                data_frame[data_frame['spiral'] == -1.0]['y'], \n",
    "                color='red', label='Classe -1.0', alpha=0.7)\n",
    "    plt.title('Treinamento do Adaline - Linha de Decisão', fontsize=16)\n",
    "    plt.xlabel('X', fontsize=14)\n",
    "    plt.ylabel('Y', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.xlim(-20, 20)\n",
    "    plt.ylim(-20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_decision_boundary(W: np.ndarray, x_axis: np.ndarray) -> None:\n",
    "    \"\"\"Atualiza a linha de decisão no gráfico.\"\"\"\n",
    "    if W[2, 0] != 0:\n",
    "        x2 = -W[1, 0] / W[2, 0] * x_axis + W[0, 0] / W[2, 0]\n",
    "        x2 = np.nan_to_num(x2)\n",
    "        plt.plot(x_axis, x2, color='orange', alpha=0.1)\n",
    "        plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_final_decision_boundary(W: np.ndarray, x_axis: np.ndarray) -> None:\n",
    "    \"\"\"Plota a linha de decisão final.\"\"\"\n",
    "    if W[2, 0] != 0:\n",
    "        x2 = -W[1, 0] / W[2, 0] * x_axis + W[0, 0] / W[2, 0]\n",
    "        x2 = np.nan_to_num(x2)\n",
    "        plt.plot(x_axis, x2, color='green', linewidth=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(\n",
    "    df: pd.DataFrame, \n",
    "    input_columns: List[str], \n",
    "    target_column: str,\n",
    "    transpose: bool = False,\n",
    "    normalize: bool = False,\n",
    "    test_size: float = 0.2, \n",
    "    random_state: int = 42,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Prepara o conjunto de dados para redes neurais, organizando entradas, saídas e divisões.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame contendo o conjunto de dados.\n",
    "        input_columns (list[str]): Lista com os nomes das colunas de entrada.\n",
    "        target_column (str): Nome da coluna de saída (rótulos).\n",
    "        transpose (bool): Transpor o DataFrame. Default é False.\n",
    "        test_size (float): Proporção do conjunto de teste (0 a 1). Default é 0.2 (20%).\n",
    "        random_state (int): Semente para reprodutibilidade da divisão. Default é 42.\n",
    "\n",
    "    Returns:\n",
    "        dict: Um dicionário contendo os conjuntos organizados:\n",
    "            - 'X_train': Entradas para treinamento.\n",
    "            - 'X_test': Entradas para teste.\n",
    "            - 'Y_train': Rótulos para treinamento.\n",
    "            - 'Y_test': Rótulos para teste.\n",
    "    \"\"\"\n",
    "    X = df[input_columns].values\n",
    "    Y = df[target_column].values\n",
    "    \n",
    "    if transpose:\n",
    "        X = X.T\n",
    "        Y = Y.T\n",
    "        \n",
    "        p, N = X.shape\n",
    "        X = np.concatenate((\n",
    "            -np.ones((1, N)),\n",
    "            X\n",
    "        ))\n",
    "        \n",
    "    else:\n",
    "        N, p = X.shape\n",
    "        X = np.concatenate((\n",
    "            -np.ones((N, 1)),\n",
    "            X\n",
    "        ), axis = 1)\n",
    "    \n",
    "    if normalize:\n",
    "        X = 2 * (X - X.min()) / (X.max() - X.min()) - 1\n",
    "\n",
    "    return {\n",
    "        'X': X,\n",
    "        'Y': Y,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1999)\n",
      "(1999,)\n"
     ]
    }
   ],
   "source": [
    "data = prepare_data(\n",
    "    df=df, \n",
    "    input_columns=[\"x\", \"y\"], \n",
    "    target_column=\"spiral\",\n",
    "    transpose=True,\n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(data['X'].shape)\n",
    "print(data['Y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_root_mean_square_error(\n",
    "    X_train: np.ndarray,\n",
    "    Y_train: np.ndarray,\n",
    "    w: np.ndarray\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calcula o erro quadrático médio.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Entradas para treinamento.\n",
    "        Y_train (np.ndarray): Rótulos para treinamento.\n",
    "        w (np.ndarray): Vetor de pesos.\n",
    "\n",
    "    Returns:\n",
    "        float: Erro quadrático médio.\n",
    "    \"\"\"\n",
    "    p_1, N = X_train.shape\n",
    "    square_error = 0\n",
    "\n",
    "    for t in range(N):\n",
    "        x_t = X_train[:, t].reshape(p_1, 1)\n",
    "        u_t = (w.T @ x_t)[0, 0]\n",
    "        d_t = Y_train[0, t]\n",
    "        square_error += (d_t - u_t)**2\n",
    "\n",
    "    return square_error / (2 * N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(\n",
    "    u: np.ndarray, \n",
    "    logistic: bool = True, \n",
    "    hyperbolic: bool = False\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Função de ativação para a rede MLP. Pode ser logística ou hiperbólica.\n",
    "    \n",
    "    Args:\n",
    "        u (np.ndarray): Vetor de entradas.\n",
    "        logistic (bool): Função logística. Default é True.\n",
    "        hyperbolic (bool): Função hiperbólica. Default é False.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Vetor de saídas.\n",
    "    \"\"\"\n",
    "    \n",
    "    if np.min(u) == np.max(u):\n",
    "        raise ValueError(\"Input array 'u' must have more than one unique value.\")\n",
    "    \n",
    "    if logistic:\n",
    "        return (u - np.min(u)) / (np.max(u) - np.min(u))\n",
    "    \n",
    "    if hyperbolic:\n",
    "        return 2 * ((u - np.min(u)) / (np.max(u) - np.min(u))) - 1\n",
    "    \n",
    "    raise ValueError(\"Either 'logistic' or 'hyperbolic' must be True.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_derivate(\n",
    "    u: np.ndarray, \n",
    "    logistic: bool = True, \n",
    "    hyperbolic: bool = False\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Derivada da função de ativação para a rede MLP. Pode ser logística ou hiperbólica.\n",
    "    \n",
    "    Args:\n",
    "        u (np.ndarray): Vetor de entradas.\n",
    "        logistic (bool): Função logística. Default é True.\n",
    "        hyperbolic (bool): Função hiperbólica. Default é False.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Vetor de saídas.\n",
    "    \"\"\"\n",
    "    \n",
    "    if np.min(u) == np.max(u):\n",
    "        raise ValueError(\"Input array 'u' must have more than one unique value.\")\n",
    "    \n",
    "    if logistic:\n",
    "        return u * (1 - u)\n",
    "    \n",
    "    if hyperbolic:\n",
    "        return 1 - u**2\n",
    "    \n",
    "    raise ValueError(\"Either 'logistic' or 'hyperbolic' must be True.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_train(\n",
    "    data: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    hidden_units: int,\n",
    "    last_layer_units: int = 1,\n",
    "    learning_rate: float = 0.01,\n",
    "    epochs: int = 100,\n",
    "    tolerance: float = 1e-3,\n",
    "    patience: int = 10,\n",
    "    transpose: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Treina uma rede MLP.\n",
    "    \n",
    "    Args:\n",
    "        data (np.ndarray): Dados de entrada.\n",
    "        labels (np.ndarray): Rótulos.\n",
    "        hidden_units (int): Número de neurônios na camada oculta.\n",
    "        last_layer_units (int): Número de neurônios na última camada. Default é 1.\n",
    "        learning_rate (float): Taxa de aprendizado. Default é 0.01.\n",
    "        epochs (int): Número máximo de épocas. Default é 100.\n",
    "        tolerance (float): Tolerância para convergência. Default é 1e-3.\n",
    "        patience (int): Paciência para early stopping. Default é 10.\n",
    "        transpose (bool): Transpor o conjunto de dados. Default é False.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Tupla contendo os pesos treinados e o histórico de erro.\n",
    "    \"\"\"\n",
    "    \n",
    "    if transpose:\n",
    "        data = data.T\n",
    "        labels = labels.T\n",
    "    \n",
    "    N, p = data.shape\n",
    "    \n",
    "    layers = [N] + hidden_units + [last_layer_units]\n",
    "    \n",
    "    weights = [np.random.randn(layers[i + 1], layers[i] + 1) * np.sqrt(2 / layers[i]) for i in range(len(layers) - 1)]\n",
    "    \n",
    "    mse_history = []\n",
    "    no_improvement = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        activations = [data]\n",
    "        z_s = []\n",
    "        \n",
    "        for w in range(len(weights)):\n",
    "            a_with_bias = np.vstack([np.ones((1, activations[-1].shape[1])), activations[-1]])\n",
    "            z = np.dot(w, a_with_bias)\n",
    "            z_s.append(z)\n",
    "            a = activation_function(u=z, logistic=False, hyperbolic=True)\n",
    "            activations.append(a)\n",
    "\n",
    "        y_pred = activations[-1]\n",
    "        mse = np.mean(np.sum((y_pred - labels) ** 2, axis=1))\n",
    "        mse_history.append(mse)\n",
    "        \n",
    "        if epoch > 0 and mse >= mse_history[-2]:\n",
    "            no_improvement += 1\n",
    "            if no_improvement >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}.\")\n",
    "                break\n",
    "        else:\n",
    "            no_improvement = 0\n",
    "        \n",
    "        if epoch > 0 and abs(mse_history[-1] - mse_history[-2]) < tolerance:\n",
    "            print(f\"Converged at epoch {epoch}.\")\n",
    "            break\n",
    "        \n",
    "        # Backpropagation\n",
    "        deltas = [None] * len(weights)\n",
    "        deltas[-1] = (y_pred - labels) * activation_derivate(u=y_pred, logistic=False, hyperbolic=True)\n",
    "        \n",
    "        for l in range(len(weights) - 2, -1, -1):\n",
    "            a_with_bias = np.vstack([np.ones((1, activations[l + 1].shape[1])), activations[l + 1]])\n",
    "            deltas[l] = np.dot(weights[l + 1][:, 1:].T, deltas[l + 1]) * activation_derivate(u=activations[l + 1], logistic=False, hyperbolic=True)\n",
    "        \n",
    "        for l in range(len(weights)):\n",
    "            a_with_bias = np.vstack([np.ones((1, activations[l].shape[1])), activations[l]])\n",
    "            weights[l] -= learning_rate * np.dot(deltas[l], a_with_bias.T) / p\n",
    "    \n",
    "    return weights, mse_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_predict(\n",
    "    data: np.ndarray,\n",
    "    weights: List[np.ndarray]\n",
    "):\n",
    "    activations = data\n",
    "    \n",
    "    for w in range(len(weights)):\n",
    "        a_with_bias = np.vstack([np.ones((1, activations.shape[1])), activations])\n",
    "        z = np.dot(w, a_with_bias)\n",
    "        activations = activation_function(u=z, logistic=False, hyperbolic=True)\n",
    "    \n",
    "    final_output = activations\n",
    "    predictions = np.argmax(final_output, axis=1)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FacialRecognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
